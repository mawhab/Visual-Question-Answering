{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riIg0bj8IbLf"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "\n",
        "od.download('https://www.kaggle.com/datasets/ingbiodanielh/vizwiz')"
      ],
      "metadata": {
        "id": "eFhvv7zcI-st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/vizwiz/data/Images | wc -l"
      ],
      "metadata": {
        "id": "dKO3pQ5guhhn",
        "outputId": "cb3ab005-a79f-4d19-e150-49444634a0da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "id": "2gPqaWaRJJSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import clip\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchtext\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "vQQPrvxML-cr"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/vizwiz/data/Images/VizWiz_train_000000000000.jpg')"
      ],
      "metadata": {
        "id": "x7Bt3X8ZZ6XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.show()"
      ],
      "metadata": {
        "id": "VKATnamsaG_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = None\n",
        "\n",
        "with open('/content/vizwiz/data/Annotations/train.json') as f:\n",
        "  data = json.load(f)"
      ],
      "metadata": {
        "id": "OOz9mpcFITJr"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "id": "eCAzin7HJGLk",
        "outputId": "5ff2dbbc-0c49-4367-f8ea-64cb2f5ae748",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = {'img': 0, 'answerable': 1, 'question': 2, 'answer_type': 3, 'answer': 4}"
      ],
      "metadata": {
        "id": "qEOKKPL6JvvP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = []\n",
        "\n",
        "for entry in data:\n",
        "  df.append([entry['image'], entry['answerable'], entry['question'], entry['answer_type'], entry['answers'][4]['answer']])\n",
        "\n",
        "df = np.array(df)"
      ],
      "metadata": {
        "id": "7BOZkF7bKLOV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "OpBL-34yKmmM",
        "outputId": "3ba6ea20-2583-4380-c993-37c46d94d62b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array([(entry[3], entry[4]) for entry in df])"
      ],
      "metadata": {
        "id": "AjfdgD_GKyr9"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = np.array([entry[4] for entry in df])"
      ],
      "metadata": {
        "id": "bbEHlXU8f58g"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_types = np.array([entry[3] for entry in df])"
      ],
      "metadata": {
        "id": "1fe_Q2_wf-7L"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "DzYxiB7UK_xu",
        "outputId": "652ae881-68a6-49fd-d46e-08651458f6b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[10]"
      ],
      "metadata": {
        "id": "VJ7_p0dlLA8c",
        "outputId": "fb1e25b9-f434-42e3-8504-855678c03766",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['other', 'samsung phone'], dtype='<U92')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, preprocess = clip.load('ViT-B/32', device=device)"
      ],
      "metadata": {
        "id": "7M3L5vFZa641"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i in range(3000):\n",
        "    encoded_img = model.encode_image(preprocess(Image.open('/content/vizwiz/data/Images/'+df[i][0])).unsqueeze(0).to(device)).to('cpu')\n",
        "    encoded_q = model.encode_text(clip.tokenize(df[i][2]).to(device)).to('cpu')\n",
        "\n",
        "    X.append([encoded_img, encoded_q])\n",
        "\n",
        "X = np.array(X)"
      ],
      "metadata": {
        "id": "Z1MaUGvdOt0J",
        "outputId": "da9852f1-4895-47b6-c15e-ca559d33a223",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-8599fef85aa1>:10: FutureWarning: The input object of type 'Tensor' is an array-like implementing one of the corresponding protocols (`__array__`, `__array_interface__` or `__array_struct__`); but not a sequence (or 0-D). In the future, this object will be coerced as if it was first converted using `np.array(obj)`. To retain the old behaviour, you have to either modify the type 'Tensor', or assign to an empty array created with `np.empty(correct_shape, dtype=object)`.\n",
            "  X = np.array(X)\n",
            "<ipython-input-27-8599fef85aa1>:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.array(X)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
        "tokenized_answers = np.array([tokenizer(answer) for answer in answers])\n",
        "print(tokenized_answers[10])"
      ],
      "metadata": {
        "id": "PWV_U4tFbN68",
        "outputId": "7cfa9840-3f23-4818-bbed-99a148458422",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['samsung', 'phone']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-6aad3a95851a>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  tokenized_answers = np.array([tokenizer(answer) for answer in answers])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = torchtext.vocab.build_vocab_from_iterator(tokenized_answers, min_freq=1)\n",
        "vocab.insert_token('<unk>', 0)\n",
        "vocab.insert_token('<eos>', 1)\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "print(len(vocab))\n",
        "print(vocab.get_itos()[:10])"
      ],
      "metadata": {
        "id": "cMURub2rcNPz",
        "outputId": "3a96228e-c9ca-4ae8-808a-a086e5216ab5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6048\n",
            "['<unk>', '<eos>', 'unanswerable', 'unsuitable', 'no', 'white', 'yes', 'black', 'blue', 'grey']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fin_answers = []\n",
        "\n",
        "for answer in tokenized_answers:\n",
        "  if answer:\n",
        "    answer.append('<eos>')\n",
        "    tokens = [vocab[token] for token in answer]\n",
        "    fin_answers.append(tokens)\n",
        "\n",
        "print(fin_answers[10])"
      ],
      "metadata": {
        "id": "vI7GYj-Tfk_g",
        "outputId": "e8eec1b1-eb0f-4586-9859-8a4a19099023",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[616, 18, 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)"
      ],
      "metadata": {
        "id": "sTOVgxoWc5d7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Custom Dataset class\n",
        "class VQADataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        label = self.labels[index]\n",
        "\n",
        "        return x, label"
      ],
      "metadata": {
        "id": "tBbAMFNud_kM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = DataLoader(VQADataset(X_train, y_train), batch_size=32)\n",
        "test_set = DataLoader(VQADataset(X_test, y_test), batch_size=32)"
      ],
      "metadata": {
        "id": "GJAc2XTIeMou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VQA_Network(nn.Module):\n",
        "    def __init__(self, num_classes, seq_len, hidden_dim):\n",
        "        super(VQA_Network, self).__init__()\n",
        "\n",
        "        self.fc = nn.Linear(embedding_dim, hidden_dim)\n",
        "        self.fc2_answers = nn.Linear(hidden_dim, seq_len)\n",
        "\n",
        "        self.fc2_aux = nn.Linear(hidden_dim, num_classes)\n",
        "        self.fc3_aux = nn.Linear(num_classes, seq_len)\n",
        "\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = x.to(dtype=torch.float32)\n",
        "        x = self.fc(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        qtype = self.fc2_aux(x)\n",
        "        aux = self.fc3_aux(qtype)\n",
        "\n",
        "        answers = self.fc2_answers(x)\n",
        "\n",
        "        answers = answers * aux\n",
        "\n",
        "        # answers = answers.to(dtype=torch.int64)\n",
        "\n",
        "        return answers, qtype\n"
      ],
      "metadata": {
        "id": "w0LAOTWvjh9w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 5726\n",
        "seq_len = 128\n",
        "hidden_dim = 512\n",
        "\n",
        "# Instantiate the model\n",
        "model = VQA_Network(num_classes, seq_len, hidden_dim).to(device)\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(200):\n",
        "    model.train()\n",
        "    running_loss_a = 0.0\n",
        "    running_loss_q = 0.0\n",
        "\n",
        "    for xs, labelset in train_set:\n",
        "        # Move data to the device\n",
        "        xs = xs.to(device)\n",
        "        labelset = labelset.to(device)\n",
        "        answerset, qtypeset = labelset\n",
        "\n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        answers, qtypes = model(xs)\n",
        "        print(xs.size())\n",
        "        print(labelset.size())\n",
        "        # Compute loss\n",
        "        answer_loss = criterion(answers, answerset)\n",
        "\n",
        "        # Backward pass\n",
        "        answer_loss.backward()\n",
        "\n",
        "        # Compute loss\n",
        "        qtype_loss = criterion(qtypes, qtypeset)\n",
        "\n",
        "        # Backward pass\n",
        "        qtype_loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update running loss\n",
        "        running_loss_a += answer_loss.item()\n",
        "        running_loss_q += qtype_loss.item()\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    average_loss_a = running_loss_a / len(data_loader)\n",
        "    average_loss_q = running_loss_q / len(data_loader)\n",
        "\n",
        "    # Print progress\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss_a: {average_loss_a:.4f}, Loss_q: {average_loss_q:.4f}\")\n",
        "\n",
        "# Training complete\n"
      ],
      "metadata": {
        "id": "V_K1-Pgwe4pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9cLyHq8Ffs65"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}