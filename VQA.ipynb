{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "riIg0bj8IbLf"
      },
      "outputs": [],
      "source": [
        "!pip install opendatasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import opendatasets as od\n",
        "\n",
        "od.download('https://www.kaggle.com/datasets/ingbiodanielh/vizwiz')"
      ],
      "metadata": {
        "id": "eFhvv7zcI-st"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content/vizwiz/data/Images | wc -l"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKO3pQ5guhhn",
        "outputId": "cb3ab005-a79f-4d19-e150-49444634a0da"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "31173\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ftfy regex tqdm\n",
        "!pip install git+https://github.com/openai/CLIP.git"
      ],
      "metadata": {
        "id": "2gPqaWaRJJSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import clip\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "import torchtext\n",
        "from PIL import Image\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "vQQPrvxML-cr"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img = Image.open('/content/vizwiz/data/Images/VizWiz_train_000000000000.jpg')"
      ],
      "metadata": {
        "id": "x7Bt3X8ZZ6XG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img.show()"
      ],
      "metadata": {
        "id": "VKATnamsaG_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = None\n",
        "\n",
        "with open('/content/vizwiz/data/Annotations/train.json') as f:\n",
        "  data = json.load(f)"
      ],
      "metadata": {
        "id": "OOz9mpcFITJr"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
        "tokenized_answers = np.array([tokenizer(answer) for answer in answers[:3000]], dtype=object)\n",
        "print(tokenized_answers[10])\n",
        "vocab = torchtext.vocab.build_vocab_from_iterator(tokenized_answers, min_freq=1)\n",
        "vocab.insert_token('<unk>', 0)\n",
        "vocab.insert_token('<eos>', 1)\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "print(len(vocab))\n",
        "print(vocab.get_itos()[:10])"
      ],
      "metadata": {
        "id": "704NPCLrFyR2",
        "outputId": "06114a6c-064c-4bbd-f842-0dbdfcebc62d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7119\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eCAzin7HJGLk",
        "outputId": "37db1797-03ba-4cf4-faf4-611850234913"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "20000"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = {'img': 0, 'answerable': 1, 'question': 2, 'answer_type': 3, 'answer': 4}"
      ],
      "metadata": {
        "id": "qEOKKPL6JvvP"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = []\n",
        "\n",
        "for entry in data:\n",
        "  df.append([entry['image'], entry['answerable'], entry['question'], entry['answer_type'], entry['answers'][4]['answer']])\n",
        "\n",
        "df = np.array(df)"
      ],
      "metadata": {
        "id": "7BOZkF7bKLOV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpBL-34yKmmM",
        "outputId": "2a6ff3fd-deb1-49f3-d650-c1debe5b120b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 5)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = np.array([(entry[3], entry[4]) for entry in df])"
      ],
      "metadata": {
        "id": "AjfdgD_GKyr9"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = np.array([entry[4] for entry in df])"
      ],
      "metadata": {
        "id": "bbEHlXU8f58g"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_len = len(max(answers,key=len))"
      ],
      "metadata": {
        "id": "eWbrrmzMtzfC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answer_types = np.array([entry[3] for entry in df])"
      ],
      "metadata": {
        "id": "1fe_Q2_wf-7L"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzYxiB7UK_xu",
        "outputId": "652ae881-68a6-49fd-d46e-08651458f6b1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y[10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VJ7_p0dlLA8c",
        "outputId": "fb1e25b9-f434-42e3-8504-855678c03766"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['other', 'samsung phone'], dtype='<U92')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model, preprocess = clip.load('ViT-B/32', device=device)"
      ],
      "metadata": {
        "id": "7M3L5vFZa641",
        "outputId": "8e35a7b2-8a68-434a-eb24-fcf2f7246fdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|████████████████████████████████████████| 338M/338M [00:03<00:00, 115MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = []\n",
        "\n",
        "with torch.no_grad():\n",
        "  for i in range(3000):\n",
        "    encoded_img = model.encode_image(preprocess(Image.open('/content/vizwiz/data/Images/'+df[i][0])).unsqueeze(0).to(device))\n",
        "    encoded_q = model.encode_text(clip.tokenize(df[i][2]).to(device))\n",
        "\n",
        "    X.append(torch.hstack([encoded_img, encoded_q]))\n",
        "\n",
        "X = torch.vstack(X)"
      ],
      "metadata": {
        "id": "Z1MaUGvdOt0J"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.size()"
      ],
      "metadata": {
        "id": "iBA2KiYz4twa",
        "outputId": "8bc7fb31-e456-4937-fffc-27eec41e2f94",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3000, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = torchtext.data.utils.get_tokenizer('basic_english')\n",
        "tokenized_answers = np.array([tokenizer(answer) for answer in answers[:3000]], dtype=object)\n",
        "print(tokenized_answers[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWV_U4tFbN68",
        "outputId": "49b69487-a69a-4c46-8028-4aaa15529d46"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['samsung', 'phone']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_answers.shape"
      ],
      "metadata": {
        "id": "X18ATgoim-A_",
        "outputId": "3810bd81-8ce2-4ce0-9bb0-33c1419eeefd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000,)"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = torchtext.vocab.build_vocab_from_iterator(tokenized_answers, min_freq=1)\n",
        "vocab.insert_token('<unk>', 0)\n",
        "vocab.insert_token('<eos>', 1)\n",
        "vocab.set_default_index(vocab['<unk>'])\n",
        "print(len(vocab))\n",
        "print(vocab.get_itos()[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMURub2rcNPz",
        "outputId": "fdec8dcb-aa77-4070-96f1-966217317101"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1900\n",
            "['<unk>', '<eos>', 'unanswerable', 'unsuitable', 'no', 'white', 'black', 'blue', 'yes', 'grey']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fin_answers = []\n",
        "\n",
        "for answer in tokenized_answers:\n",
        "  answer.append('<eos>')\n",
        "  tokens = np.array([vocab[token] for token in answer])\n",
        "  fin_answers.append(np.pad(tokens, (0,max_len-len(tokens))))\n",
        "\n",
        "fin_answers = np.array(fin_answers)\n",
        "print(fin_answers[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vI7GYj-Tfk_g",
        "outputId": "a6cdd021-553a-4410-eef6-72541e766926"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[540  14   1   1   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
            "   0   0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fin_answers.shape"
      ],
      "metadata": {
        "id": "gPiwiqsb4WJv",
        "outputId": "8e2d1199-c0d6-41b2-b9f5-6adc374a84f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 92)"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "encoded_answer_types = le.fit_transform(answer_types)\n",
        "\n",
        "print(encoded_answer_types[10])"
      ],
      "metadata": {
        "id": "jWct5pBRmMJo",
        "outputId": "130ce37e-2519-46f4-f772-1e1db012df46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le.classes_"
      ],
      "metadata": {
        "id": "MCLsMAE313sT",
        "outputId": "c1614be4-f8e4-408a-a251-ff5268f7ae58",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['number', 'other', 'unanswerable', 'yes/no'], dtype='<U12')"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = [(a_type, a) for a_type, a in zip(encoded_answer_types, fin_answers)]\n",
        "# y = np.array(y, dtype=object)"
      ],
      "metadata": {
        "id": "vfQLzWjgmntz"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y.shape"
      ],
      "metadata": {
        "id": "cWMJNyzgmy4Z",
        "outputId": "1e0e7173-3d8d-426f-f257-ee253287adb4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.05, random_state=42)"
      ],
      "metadata": {
        "id": "sTOVgxoWc5d7"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# Custom Dataset class\n",
        "class VQADataset(Dataset):\n",
        "    def __init__(self, data, labels):\n",
        "        self.data = data\n",
        "        self.qtypes = []\n",
        "        self.answers = []\n",
        "        for qtype, ans in labels:\n",
        "          self.qtypes.append(qtype)\n",
        "          self.answers.append(ans)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        x = torch.Tensor(self.data[index])\n",
        "        qy, ay = self.qtypes[index], torch.Tensor(self.answers[index])\n",
        "\n",
        "        return x, qy, ay"
      ],
      "metadata": {
        "id": "tBbAMFNud_kM"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_set = DataLoader(VQADataset(X_train, y_train), batch_size=32)\n",
        "test_set = DataLoader(VQADataset(X_test, y_test), batch_size=32)"
      ],
      "metadata": {
        "id": "GJAc2XTIeMou"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VQA_Network(nn.Module):\n",
        "    def __init__(self, num_classes, seq_len, hidden_dim, embedding_dim):\n",
        "        super(VQA_Network, self).__init__()\n",
        "\n",
        "        self.fc = nn.Linear(embedding_dim, hidden_dim)\n",
        "        self.fc2_answers = nn.Linear(hidden_dim, seq_len)\n",
        "\n",
        "        self.fc2_aux = nn.Linear(hidden_dim, num_classes)\n",
        "        self.fc3_aux = nn.Linear(num_classes, seq_len)\n",
        "\n",
        "        self.norm = nn.LayerNorm(hidden_dim)\n",
        "        self.dropout = nn.Dropout()\n",
        "        self.softmax = nn.Softmax(dim=0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x.to(dtype=torch.float32)\n",
        "        x = self.fc(x)\n",
        "        x = self.norm(x)\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        qtype = self.fc2_aux(x)\n",
        "        aux = self.fc3_aux(qtype)\n",
        "\n",
        "        answers = self.fc2_answers(x)\n",
        "\n",
        "        answers = answers * self.softmax(aux)\n",
        "\n",
        "        # answers = answers.to(dtype=torch.int64)\n",
        "\n",
        "        return answers, qtype\n"
      ],
      "metadata": {
        "id": "w0LAOTWvjh9w"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 4\n",
        "seq_len = 92\n",
        "hidden_dim = 512\n",
        "embedding_dim = 1024\n",
        "\n",
        "num_epochs = 200\n",
        "\n",
        "# Instantiate the model\n",
        "model = VQA_Network(num_classes, seq_len, hidden_dim, embedding_dim).to(device)\n",
        "\n",
        "# Define loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss_a = 0.0\n",
        "    running_loss_q = 0.0\n",
        "\n",
        "    for xs, qtypeset, answerset in train_set:\n",
        "        # Move data to the device\n",
        "        xs = xs.to(device)\n",
        "        qtypeset = qtypeset.to(device)\n",
        "        answerset = answerset.to(device)\n",
        "\n",
        "        # Clear gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        answers, qtypes = model(xs)\n",
        "        # print(xs.size())\n",
        "        # print(labelset.size())\n",
        "        # Compute loss\n",
        "        answer_loss = criterion(answers, answerset)\n",
        "\n",
        "        # Backward pass\n",
        "        answer_loss.backward(retain_graph=True)\n",
        "\n",
        "        # Compute loss\n",
        "        qtype_loss = criterion(qtypes, qtypeset)\n",
        "\n",
        "        # Backward pass\n",
        "        qtype_loss.backward()\n",
        "\n",
        "        # Update weights\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update running loss\n",
        "        running_loss_a += answer_loss.item()\n",
        "        running_loss_q += qtype_loss.item()\n",
        "\n",
        "    # Calculate average loss for the epoch\n",
        "    average_loss_a = running_loss_a / len(train_set)\n",
        "    average_loss_q = running_loss_q / len(train_set)\n",
        "\n",
        "    # Print progress\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss_a: {average_loss_a:.4f}, Loss_q: {average_loss_q:.4f}\")\n",
        "\n",
        "# Training complete\n"
      ],
      "metadata": {
        "id": "V_K1-Pgwe4pg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[1]"
      ],
      "metadata": {
        "id": "Sbg9bho0BcSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_test[3]"
      ],
      "metadata": {
        "id": "Mp5kfukWCdV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model(X_test[3]))"
      ],
      "metadata": {
        "id": "8kYm-m3tCes3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}